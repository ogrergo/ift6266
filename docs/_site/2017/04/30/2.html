
<h1 id="results">Results</h1>

<p>It is difficult to evaluate this model, because there is no clear metric to measure the “realness” of images.</p>

<p>Here some of the results I get:
<img src="/home/louis/code/ift6266/docs/static_files/random.jpg" alt="alt text" title="Results" /></p>

<p>I have tried to generate with false captions, to see if the generator have learnt to use them :
<img src="/home/louis/code/ift6266/docs/static_files/wrong_captions.jpg" alt="alt text" title="Wrong captions" /></p>

<p>We not see some clear difference. I think the conditioning on the caption is not significant in this generator model. However, the loss <code class="highlighter-rouge">Ld_fake_captions</code>
go to zero on the discriminator, that mean that the discriminator predict the reject class (0) for images from the dataset with an invalid caption. The discriminator is then able to use the information contained in the embeddings.
Then the generator inability to
In future work, I should see to a better conditioning on the caption in the generator.</p>

<p>But we can instead experiment a variation on the conditioning to observe the dependance the model have learn on it.</p>
